Here is a list of papers that were influential in my research development based on each year. Not a comprehensive list, just some that I really liked.

# 2021 

- Evolving Reinforcement Learning Algorithms: https://openreview.net/pdf?id=0XXpJ4OtjW
- Evolving the Behavior of Machines: From Micro to Macroevolution: https://www.sciencedirect.com/science/article/pii/S2589004220309287
- Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science https://www.nature.com/articles/s41467-018-04316-3?fbclid=IwAR2Q-t4B23NCAjiM8y1ehyAV5cgP_NPMG6zo-8YDLR9OLQMu1TzW_AyIyvQ
- Artificial Neurogenesis: An Introduction and Selective Review: https://hal.archives-ouvertes.fr/hal-01351738/document
- The past, present, and future of artificial life: https://www.frontiersin.org/articles/10.3389/frobt.2014.00008/full
- Complex Adaptations and the Evolution of Evolvability: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.1524&rep=rep1&type=pdf
- How evolution learns to generalise: Using the principles of learning theory to understand the evolution of developmental organisation: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005358 


# 2020 
### \[The year of Evolution, Philosophy, and Biology\]
**Paper of the Year**: AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence https://arxiv.org/pdf/1905.10985.pdf

- Weight Agnostic Neural Networks https://arxiv.org/pdf/1906.04358.pdf
- Meta-Learning through Hebbian Plasticity in Random Networks: https://arxiv.org/abs/2007.02686 (One of my favorite papers ever)
- The Road to Everywhere: Evolution, Complexity and Progress in Natural and Artificial Systems : https://etheses.bham.ac.uk//id/eprint/148/1/Miconi08PhD.pdf
- ES Is More Than Just a Traditional Finite-Difference Approximator: https://arxiv.org/pdf/1712.06568.pdf
- Deep Neuroevolution: Genetic Algorithms are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning https://arxiv.org/pdf/1712.06567.pdf
- The Evolution of Learning: An Experiment in Genetic Connectionism: http://consc.net/papers/evolution.pdf
- Evolution Strategies as a Scalable Alternative to Reinforcement Learning: https://arxiv.org/pdf/1703.03864.pdf
- Evolving to learn: discovering interpretable plasticity rules for spiking networks https://arxiv.org/pdf/2005.14149.pdf
- Eligibility Traces and Plasticity on Behavioral Time Scales https://www.frontiersin.org/articles/10.3389/fncir.2018.00053/full
- A solution to the learning dilemma for recurrent networks of spiking neurons https://www.nature.com/articles/s41467-020-17236-y
- A distributional code for value in dopamine-based reinforcement learning: https://deepmind.com/research/publications/A-distributional-code-for-value-in-dopamine-based-reinforcement-learning
- Learning with Plasticity Rules: Generalization and Robustness https://openreview.net/pdf?id=XEyElxd9zji
- Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic Artificial Neural Networks https://arxiv.org/abs/1703.10371
- Efficient Reinforcement Learning through Evolving Neural Network Topologies http://nn.cs.utexas.edu/downloads/papers/stanley.gecco02_1.pdf
- An Enhanced Hypercube-Based Encoding for Evolving the Placement, Density and Connectivity of Neurons https://eplex.cs.ucf.edu/papers/risi_alife12.pdf 
- How Learning Can Guide Evolution https://content.wolfram.com/uploads/sites/13/2018/02/01-3-6.pdf
- Hypernetworks https://arxiv.org/pdf/1609.09106.pdf
- A critique of pure learning and what artificial neural networks can learn from animal brains https://www.nature.com/articles/s41467-019-11786-6
- Testing the Genomic Bottleneck Hypothesis in Hebbian Meta-Learning https://arxiv.org/pdf/2011.06811.pdf
- IMPROVING DEEP NEUROEVOLUTION VIA DEEP INNOVATION PROTECTION https://arxiv.org/pdf/2001.01683.pdf
- Compositional Pattern Producing Networks: A Novel Abstraction of Development https://eplex.cs.ucf.edu/papers/stanley_gpem07.pdf
- On the Relationships between Generative Encodings, Regularity, and Learning Abilities when Evolving Plastic Artificial Neural Networks https://pubmed.ncbi.nlm.nih.gov/24236099/
- Network of evolvable neural units can learn synaptic learning rules and spiking dynamics https://www.nature.com/articles/s42256-020-00267-x
- Neuroevolution of Self-Interpretable Agents https://attentionagent.github.io/
- Recurrent World Models Facilitate Policy Evolution https://papers.nips.cc/paper/2018/file/2de5d16682c3c35007e4e92982f1a2ba-Paper.pdf
- Driven by Compression Progress: A Simple Principle Explains Essential Aspects ... https://arxiv.org/abs/0812.4360
- The Body is Not a Given: Joint Agent Policy Learning and Morphology Evolution https://openreview.net/forum?id=BJgWl3A5YX
- Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity https://arxiv.org/pdf/1902.05546.pdf
- Indirectly Encoding Neural Plasticity as a Pattern of Local Rules https://eplex.cs.ucf.edu/papers/risi_sab10.pdf
- Deep Reinforcement Learning with Population-Coded Spiking Neural Network for Continuous Control https://arxiv.org/abs/2010.09635
- Strong inhibitory signaling underlies stable temporal dynamics and working memory in spiking neural networks https://www.nature.com/articles/s41593-020-00753-w
- SLAYER: Spike Layer Error Reassignment in Time https://arxiv.org/abs/1810.08646
- Deep Learning With Spiking Neurons: Opportunities and Challenges https://www.frontiersin.org/articles/10.3389/fnins.2018.00774/full
- An Astrocyte-Modulated Neuromorphic Central Pattern Generator for Hexapod Robot Locomotion on Intelâ€™s Loihi https://arxiv.org/pdf/2006.04765.pdf
- Networks of Spiking Neurons: The Third Generation of Neural Network Models https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf
- Eligibility traces provide a data-inspired alternative to backpropagation through time https://openreview.net/pdf?id=SkxJ4QKIIS
- Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs https://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns
- Learning Task-Driven Control Policies via Information Bottlenecks https://arxiv.org/pdf/2002.01428v1.pdf
- Learning to Learn with Feedback and Local Plasticity https://openreview.net/pdf?id=HklfNQFL8H
- Structured and Deep Similarity Matching via Structured and Deep Hebbian Networks http://papers.nips.cc/paper/9674-structured-and-deep-similarity-matching-via-structured-and-deep-hebbian-networks.pdf
- Assessing the scalability of biologically-motivated deep learning algorithms
and architectures https://papers.nips.cc/paper/8148-assessing-the-scalability-of-biologically-motivated-deep-learning-algorithms-and-architectures.pdf
- A mesoscale connectome of the mouse brain https://www.nature.com/articles/nature13186
- Neocortical layer 6, a review https://www.frontiersin.org/articles/10.3389/fnana.2010.00013/full
- Brain-Like Object Recognition with High-Performing Shallow Recurrent ANNs https://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns
- How well do deep neural networks trained on object recognition characterize the mouse visual system? https://openreview.net/pdf?id=rkxcXmtUUS
- Performance-optimized hierarchical models predict neural responses in higher visual cortex https://www.pnas.org/content/111/23/8619
- Neural Map: Structured Memory for Deep Reinforcement Learning https://openreview.net/pdf?id=Bk9zbyZCZ
- Cognitive Mapping and Planning for Visual Navigation http://openaccess.thecvf.com/content_cvpr_2017/papers/Gupta_Cognitive_Mapping_and_CVPR_2017_paper.pdf
- Significance of feedforward architectural differences between the ventral visual stream and DenseNet https://openreview.net/pdf?id=SkegNmFUIS
- How well do deep neural networks trained on object recognition characterize the mouse visual system? https://openreview.net/pdf?id=rkxcXmtUUS
- Neural networks grown and self-organized by noise http://papers.nips.cc/paper/by-source-2019-1100
- Densely connected convolutional networks https://arxiv.org/pdf/1608.06993.pdf
- Surround Modulation: A Bio-inspired Connectivity Structure for Convolutional Neural Networks http://papers.nips.cc/paper/9719-surround-modulation-a-bio-inspired-connectivity-structure-for-convolutional-neural-networks.pdf
- A neural network model of flexible grasp movement generation https://www.biorxiv.org/content/10.1101/742189v1.full.pdf
- Deep Neural Networks and Visual Processing in the Rat https://www.researchgate.net/publication/326547016
- BioLSTMs https://papers.nips.cc/paper/6631-cortical-microcircuits-as-gated-recurrent-neural-networks.pdf
- Neuron densities of mouse brain https://www.frontiersin.org/articles/10.3389/fnana.2018.00083/full
- Hierarchical Visuomotor Control of Humanoids https://arxiv.org/pdf/1811.09656v1.pdf
- Deep Neuroethology of a Virtual Rodent https://arxiv.org/pdf/1911.09451.pdf
- Hierarchical RL Using an Ensemble of Proprioceptive Periodic Policies https://openreview.net/pdf?id=SJz1x20cFQ
- Learning Multi-level Hierarchies with Hindsight https://arxiv.org/pdf/1712.00948.pdf
- Sub-Policy Adaptation for Hierarchical Reinforcement Learning https://openreview.net/pdf?id=ByeWogStDS


# 2019
### \[The year of RL and Theory\]
**Paper of the Year**: Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity: https://arxiv.org/abs/2002.10585

- ImageNet Classification with Deep Convolutional Neural Networks: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
- Deep Residual Learning for Image Recognition: https://arxiv.org/pdf/1512.03385.pdf
- Dropout: https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf
- Net2Net: https://arxiv.org/abs/1511.05641
- Adam: https://arxiv.org/pdf/1412.6980.pdf
- Generalized Adversarial Nets: http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf
- Unsupervised Representation Learning With Deep Convolutional GANs: https://arxiv.org/pdf/1511.06434.pdf
- Neural networks with differentiable structure: https://arxiv.org/abs/1606.06216
- Differentiable plasticity- training plastic neural networks with backpropagation: https://arxiv.org/pdf/1804.02464.pdf
- Learning to learn with backpropagation of Hebbian plasticity: https://arxiv.org/abs/1609.02228
- The Effect of Network Width on Stochastic Gradient Descent
and Generalization: an Empirical Study: https://arxiv.org/pdf/1905.03776v1.pdf
- Topology of Learning in Artificial Neural Networks: https://arxiv.org/pdf/1902.08160v1.pdf
- Deep Spiking Neural Networks: https://www.research.manchester.ac.uk/portal/files/66046364/FULL_TEXT.PDF
- Deep Learning in Spiking Neural Networks: https://arxiv.org/abs/1804.08150
- Deep Spiking Nets: https://arxiv.org/pdf/1602.08323.pdf
- Noisy Softplus: https://link.springer.com/chapter/10.1007/978-3-319-46681-1_49
- Gated Feedback Recurrent Neural Networks: https://arxiv.org/pdf/1502.02367v3.pdf
- Sequence to Sequence Learning with Neural Networks: https://arxiv.org/pdf/1409.3215.pdf
- PredRNN: https://papers.nips.cc/paper/6689-predrnn-recurrent-neural-networks-for-predictive-learning-using-spatiotemporal-lstms.pdf
- Generating Sequences With Recurrent Neural Networks: https://arxiv.org/pdf/1308.0850.pdf
- Generative Adversarial Networks: https://arxiv.org/abs/1406.2661
- SeqGAN: https://arxiv.org/pdf/1609.05473.pdf
- ** A Brief Survey of Deep Reinforcement Learning: https://arxiv.org/pdf/1708.05866.pdf **
- Dueling Network Architectures for Deep Reinforcement Learning: https://arxiv.org/pdf/1511.06581.pdf
- Playing atari with deep reinforcement learning: https://arxiv.org/pdf/1312.5602.pdf
- Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm: https://arxiv.org/pdf/1712.01815.pdf
- Human-level control through deep reinforcement learning: https://storage.googleapis.com/deepmind-data/assets/papers/DeepMindNature14236Paper.pdf
- Emergence of Locomotion Behaviours in Rich Environments: https://arxiv.org/abs/1707.02286
- Proximal Policy Optimization Algorithms: https://arxiv.org/abs/1707.06347
- Trust Region Policy Optimization https://arxiv.org/abs/1502.05477
    * An objective function was proposed that [penalizes] moving away (gradient-wise) from the original distribution.
- Sim-to-Real: Learning Agile Locomotion For Quadruped Robots: https://arxiv.org/abs/1804.10332
- Soft Actor-Critic: https://arxiv.org/pdf/1801.01290.pdf
- Exploration by Random Network Distilations: https://arxiv.org/pdf/1810.12894.pdf
- Deep Recurrent Q-Learning for Partially Observable MDPs: https://arxiv.org/pdf/1507.06527.pdf (Personal Favorite)
- Challenges of Real-World Reinforcement Learning: https://openreview.net/pdf?id=S1xtR52NjN
- Understanding the Impact of Entropy on Policy Optimization: https://arxiv.org/pdf/1811.11214.pdf
- On the role of neurogenesis in overcoming catastrophic forgetting: https://marcpickett.com/cl2018/CL-2018_paper_31.pdf
- Continual Learning with Deep Generative Replay: https://papers.nips.cc/paper/6892-continual-learning-with-deep-generative-replay.pdf
- Robust Recovery Controller for a Quadrupedal Robot using Deep Reinforcement Learning: https://arxiv.org/pdf/1901.07517.pdf
- Where Should I Walk? Predicting Terrain Properties from Images via Self-Supervised Learning: http://n.ethz.ch/~cesarc/files/RAL2019_lwellhausen.pdf
- Stabilizing Task-based Omnidirectional Quadruped Locomotion with Virtual Model Control https://www.nrl.navy.mil/itd/aic/sites/www.nrl.navy.mil.itd.aic/files/pdfs/MERLIN_conf_ICRA_2015_final_v3.1.pdf
- Hierarchical Reinforcement Learning for Quadruped Locomotion https://arxiv.org/pdf/1905.08926.pdf
- WHY DOES HIERARCHY (SOMETIMES) WORK SO WELL IN REINFORCEMENT LEARNING? https://arxiv.org/pdf/1909.10618v1.pdf
- Policies Modulating Trajectory Generators http://proceedings.mlr.press/v87/iscen18a/iscen18a.pdf
- Learning Agile and Dynamic Motor Skills for Legged Robots: https://arxiv.org/abs/1901.08652
- Random network distillation: https://arxiv.org/abs/1810.12894
- LEARNING LOCOMOTION SKILLS USING DEEPRL: DOES THE CHOICE OF ACTION SPACE MATTER? https://arxiv.org/pdf/1611.01055.pdf
- Evolution Strategies as a Scalable Alternative to Reinforcement Learning https://arxiv.org/pdf/1703.03864.pdf



<ins>End of 2020 Retrospective for 2019</ins>:

During this year I was just beginning to show an interest in the more historical papers that the trending SOTA ML papers were building off of, while also for the first time developing a specialized interest in reinforcement learning and biologically inspired techniques. I think I was in the headspace of gradient supremecy that I think many beginning ML researchers find themselves in, not really exploring much outside of the mainstream umbrella. In 2020 I began working with spiking neural networks, which really opened my eyes to how narrow-sighted the NeurIPS/ICML/ICLR workspace is, and catapulted me toward learning a much larger variety of inspired techniques from evolutionary methods, STDP/plasticity methods, genetic programming, etc in 2020. I do think having a baseline understanding of the traditional gradient method papers is valuable, however I would encourage others to really delve into other sectors of the ML field for inspiration. Otherwise, I also worked closely with two talented advisors of vastly different mindsets; both from a robotics background interested in reinforcement learning. I think one of the central cultural shifts in the field will have to be shifting toward less usage of gradient methods since those methods focus to optimize the performance of a single agent, and hence generally lead to a much brittler performing agent which obviously wouldn't generalize well to the real world except on few tasks. Perhaps population-based gradient methods, or evolutionary methods, which optimize reward for a population surrouning a parameter vector, would perform much better since the parameter perturbation robustness would in theory also lead to less sensitivity to input and output noise. I think the community also has a long way to go in terms of the acceptance of evolutionary and genetic algorithm optimization. It was a shame to see both two of the most impactful papers of the year in genetic and evolutionary computing being rejected from mainstream conferences by Salimans and Clune. Interested to see how I think about all of this next year!


